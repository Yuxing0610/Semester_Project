{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_device(dataset, device = None):\n",
    "    tensor_list_X, tensor_list_Y = [], []\n",
    "    for x, y in dataset:\n",
    "        tensor_list_X.append(x)\n",
    "        tensor_list_Y.append(y)\n",
    "    \n",
    "    X = torch.stack(tensor_list_X)\n",
    "    Y = torch.tensor(tensor_list_Y)\n",
    "    if device is not None:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "    return torch.utils.data.TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dl(batch_size_train = 256, batch_size_valid = 1024, device = None):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    data_train = MNIST('./datasets', train = True, download = True, transform = transform)\n",
    "    data_train = switch_to_device(data_train, device)\n",
    "    data_train, data_valid = torch.utils.data.random_split(data_train, [55000, 5000])\n",
    "\n",
    "    data_test = MNIST('./datasets', train = False, download = True, transform = transform)\n",
    "    data_test = switch_to_device(data_test, device)\n",
    "\n",
    "    train_dl = DataLoader(data_train, batch_size = batch_size_train, shuffle = True)\n",
    "    valid_dl = DataLoader(data_valid, batch_size = batch_size_valid, shuffle = False)\n",
    "    test_dl = DataLoader(data_test, batch_size = batch_size_valid, shuffle = False)\n",
    "\n",
    "    return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(stats):\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2,figsize=(7,3), dpi=110)\n",
    "  ax1.grid()\n",
    "  ax2.grid()\n",
    "\n",
    "  ax1.set_title(\"ERM loss\")\n",
    "  ax2.set_title(\"Valid Acc\")\n",
    "  \n",
    "  ax1.set_xlabel(\"iterations\")\n",
    "  ax2.set_xlabel(\"iterations\")\n",
    "\n",
    "  itrs = [x[0] for x in stats['train-loss']]\n",
    "  loss = [x[1] for x in stats['train-loss']]\n",
    "  ax1.plot(itrs, loss)\n",
    "\n",
    "  itrs = [x[0] for x in stats['valid-acc']]\n",
    "  acc = [x[1] for x in stats['valid-acc']]\n",
    "  ax2.plot(itrs, acc)\n",
    "\n",
    "  ax1.set_ylim(0.0, 20.05)\n",
    "  ax2.set_ylim(0.0, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    @torch.no_grad()\n",
    "    def __init__ (self, input_num, output_num, num_forward_grad, device):\n",
    "        self.device = device\n",
    "        self.input_num, self.output_num = input_num, output_num\n",
    "        self.num_forward_grad = num_forward_grad\n",
    "        self.weights = torch.normal(mean = torch.full((self.input_num, self.output_num), 0.), std = torch.full((self.input_num, self.output_num), 0.1)).to(device)\n",
    "        self.bias = torch.normal(mean = torch.full((1, self.output_num), 0.), std = torch.full((1, self.output_num), 0.1)).to(device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input, da = None):\n",
    "        self.noise = torch.randn(self.num_forward_grad, 1, self.output_num, device = self.device)\n",
    "        entry_from_batch = torch.randint(low=0, high=len(input), size=[])\n",
    "        inpt = input[entry_from_batch].view(-1)[:, None]\n",
    "        inpt /= inpt.norm()\n",
    "        self.vectorw = inpt @ self.noise\n",
    "        self.vectorb = torch.randn(self.num_forward_grad, 1, self.output_num, device= self.device)\n",
    "        res = input @ self.weights + self.bias\n",
    "        if torch.is_tensor(da):\n",
    "            new_da = da @ self.weights + input @ self.vectorw + self.vectorb\n",
    "        else:\n",
    "            new_da = input @ self.vectorw + self.vectorb\n",
    "        return res, new_da\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update(self, da, lr):\n",
    "        g_w = da*self.vectorw\n",
    "        g_w = torch.sum(g_w, dim = 0)/self.num_forward_grad\n",
    "        g_b = da*self.vectorb\n",
    "        g_b = torch.sum(g_b, dim = 0)/self.num_forward_grad\n",
    "        self.weights -= lr*g_w\n",
    "        self.bias -= lr*g_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    @torch.no_grad()\n",
    "    def __init__ (self, device):\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input, da):\n",
    "        res = (torch.abs(input) + input) / 2.0\n",
    "        mask = torch.zeros(da.shape).to(self.device)\n",
    "        new_da = torch.where(da>0, da, mask)\n",
    "        return res, new_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax():\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input, da):\n",
    "        batch_size = input.shape[0]\n",
    "        x = torch.exp(input)\n",
    "        y = torch.sum(x, axis = 1).reshape(batch_size, 1)\n",
    "        res = x/y\n",
    "        new_da = torch.empty([da.shape[0], input.shape[0], input.shape[1]], dtype = float).to(DEVICE)\n",
    "        for i in range(batch_size):\n",
    "            x = torch.diag(res[i]) - torch.outer(res[i], res[i])\n",
    "            for j in range(da.shape[0]):\n",
    "                new_da[j][i] = da[j][i].reshape((1, input.shape[1])) @ x\n",
    "        return res, new_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy():\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input, da, labels):\n",
    "        loss = torch.sum(-(labels*torch.log(input))) / input.shape[0]\n",
    "        new_da = torch.empty([da.shape[0], 1, 1], dtype = float).to(DEVICE)\n",
    "        for i in range(da.shape[0]):\n",
    "            new_da[i] = torch.sum(labels*(-1/input)*da[i]) / input.shape[0]\n",
    "        return loss, new_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Nets():\n",
    "    def __init__(self, num_forward_grad, device):\n",
    "        self.device = device\n",
    "        self.fc_1 = Linear(input_num = 28*28, output_num = 1024, num_forward_grad = num_forward_grad, device = self.device)\n",
    "        self.sigmoid_1 = Relu(self.device)\n",
    "        self.fc_2 = Linear(input_num = 1024, output_num = 1024, num_forward_grad = num_forward_grad, device = self.device)\n",
    "        self.sigmoid_2 = Relu(self.device)\n",
    "        self.fc_3 = Linear(input_num = 1024, output_num = 10, num_forward_grad = num_forward_grad, device = self.device)\n",
    "        self.softmax = softmax()\n",
    "        self.CrossEntropy = CrossEntropy()\n",
    "        self.output = None\n",
    "        self.loss = None\n",
    "\n",
    "    def forward(self, input, labels):\n",
    "        input = torch.reshape(input, (input.shape[0], 28*28))\n",
    "        da = None\n",
    "        output, da = self.fc_1.forward(input)\n",
    "        output, da = self.sigmoid_1.forward(output, da)\n",
    "        output, da = self.fc_2.forward(output, da)\n",
    "        output, da = self.sigmoid_2.forward(output, da)\n",
    "        output, da = self.fc_3.forward(output, da)\n",
    "        self.output = output\n",
    "        output, da = self.softmax.forward(output, da)\n",
    "        loss, da = self.CrossEntropy.forward(output, da, labels)\n",
    "        self.loss = loss\n",
    "        self.da = da\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.fc_1.update(self.da, lr)\n",
    "        self.fc_2.update(self.da, lr)\n",
    "        self.fc_3.update(self.da, lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acc(model, dl, lr):\n",
    "  acc = []\n",
    "  for X, y in dl:\n",
    "    one_hot_y = torch.zeros(X.shape[0], 10).to(DEVICE)\n",
    "    one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "    model.forward(X, one_hot_y)\n",
    "    acc.append(torch.argmax(model.output, dim=1) == y)\n",
    "    model.update(lr)\n",
    "  acc = torch.cat(acc)\n",
    "  acc = torch.sum(acc)/len(acc)\n",
    "  return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, train_dl, valid_dl, test_dl, max_epochs=20, lr = 1e-3):\n",
    "\n",
    "  itr = -1\n",
    "  stats = {'train-loss': [], 'valid-acc':[]}\n",
    "  time_list = []\n",
    "  for epoch in range(max_epochs):\n",
    "    for X, y in train_dl:\n",
    "        itr += 1\n",
    "        one_hot_y = torch.zeros(X.shape[0], 10).to(DEVICE)\n",
    "        one_hot_y[[i for i in range(X.shape[0])], [k.item() for k in y]] = 1\n",
    "        start = time.time()\n",
    "        model.forward(X, one_hot_y)\n",
    "        model.update(lr)\n",
    "        time_list.append(time.time()-start)\n",
    "        stats['train-loss'].append((itr, model.loss.item()))\n",
    "\n",
    "        if itr % 100 == 0:\n",
    "\n",
    "          valid_acc = get_acc(model, valid_dl, lr)\n",
    "          stats['valid-acc'].append((itr, valid_acc))\n",
    "          s = f\"{epoch}:{itr} [train] loss:{model.loss.item():.3f}, [valid] acc:{valid_acc:.3f}, time: {np.sum(time_list)/100} \"\n",
    "          print(s)\n",
    "          time_list = []\n",
    "\n",
    "  test_acc = get_acc(model, test_dl, lr)\n",
    "  print(f\"[test] acc:{test_acc:.3f}\")\n",
    "  return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "train_batch = 256\n",
    "valid_batch = 1024\n",
    "lr = 1e-4\n",
    "num_forward_grad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5eaf2de9f62f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mnist_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_Nets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_forward_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f3a58bf4b51d>\u001b[0m in \u001b[0;36mget_mnist_dl\u001b[1;34m(batch_size_train, batch_size_valid, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./datasets'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswitch_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e46e817d993a>\u001b[0m in \u001b[0;36mswitch_to_device\u001b[1;34m(dataset, device)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mswitch_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtensor_list_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_list_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtensor_list_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtensor_list_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, test_dl = get_mnist_dl(batch_size_train=train_batch, batch_size_valid=valid_batch, device=DEVICE)\n",
    "\n",
    "model = MLP_Nets(num_forward_grad, DEVICE)\n",
    "\n",
    "stats = run_experiment(model, train_dl, valid_dl, test_dl, max_epochs=max_epochs, lr = lr)\n",
    "\n",
    "print_stats(stats)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
